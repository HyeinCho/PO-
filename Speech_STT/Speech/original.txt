3차 발표를 맡은 A3조 신정우입니다. 저희의 주제는 발표 연습 도우미인 포레젠테이션입니다. 목차는 다음과 같습니다. 저희 프로젝트 추진 배경입니다. 스피치 상황이 많아진 자기 PR 시대에 발표 능력 향상을 목표로 하는 소비자의 needs가 증가하고 있습니다. 그리고 발표를 두려워하거나 발표 능력이 부족한 사람들을 위한 서비스가 부재하기 때문에 발표 연습을 도와주는 AI프로젝트를 계획하게 됐습니다. 현재 기술현황으로는 마이크로소프트에서 제공하는 프레젠테이션 코치와 면접연습 AI인 뷰인터가 있습니다. 프레젠테이션 코치의 경우, 필러 유무 서비스 등의 장점이 있지만, 파워포인트에서만 이용이 가능하고, 영어로만 사용이 가능하다는 단점이 있습니다. 그래서 포레젠테이션에서는 노션, 프레지 등 다양한 발표 도구를 사용할 수 있으며, 한국어 발표 연습이 가능하도록 목표를 설정했습니다. 뷰인터의 경우 영상을 통해 시각과 음성을 분석하는 서비스를 제공하는데 이 기술을 참고하여 시선처리와 표정으로 시각분석을 하고 대본과 실제 발표 음성을 비교하여 분석하는 것을 목표로 설정했습니다. 포레젠테이션의 시스템 구조는 발표 대본을 먼저 업로드하고 발표 영상을 녹화하면 gaze tracking과 감정인식으로 시각분석을 하고, 실제 발표를 STT를 이용하여 Text화 시켜서 Word2Vec로 업로드한 대본과 비교하여 음성분석을 합니다. 그리고 STT에서 나온 단어 수를 파악해 말의 속도, 자주 사용하는 단어 등을 결과 레포트에 나타낼 것입니다. 발표가 끝나면 이러한 결과들을 보고서에 출력한 후, 발표 연습을 끝내거나 만족하지 못할 경우 대본을 재 업로드하거나 발표 연습을 다시하는 구조입니다. 다음으로 사용하는 기술을 소개하겠습니다. Gaze Tracking의 경우는 사용자의 시선이 화면에서 극단적으로 벗어나는 경우를 의심수준으로 설정하고 그 횟수를 파악할 것입니다. Emotion Recognition의 경우 발표자의 표정 중 엥그리 뉴트럴 해피를 인식하고 그 결과를 시계열 그래프로 나타내여 결과 보고서에 출력할 것입니다. STT는 사용자의 말하기를 문자로 바꿔서 실제 발표 내용을 확인하여 발표능력 피드백에 활용할 것입니다. Word2Vec과 코엔엘파이를 사용해서 업로드한 대본과 STT를 이용하여 만든 텍스트를 비교하여 단어별로 유사도를 체크할 것입니다. 먼저 시각분석 진행현황입니다. 사진에서 빨간 네모박스를 보시면 Emotion Recognition을 하는 것으로 표정을 인식하여 현재 사진에는 뉴트럴이 나타나고 있습니다. 눈동자에는 초록색 십자가 표시가 있는데 gaze tracking을 하는 것입니다.